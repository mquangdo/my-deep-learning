{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1be5273b-796e-49b1-9a13-53b000d2e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1623014e-bf2a-4517-934b-1841f9d7cb71",
   "metadata": {},
   "source": [
    "# Scalar function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a26e00ab-1299-4fc9-9883-a07cf15967ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3238, 0.0090, 0.1217], requires_grad=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3, requires_grad = True)\n",
    "x #Vector cần tính đạo gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9560269d-1716-4cdf-b70c-4947e5c7e71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6477, 0.0180, 0.2435])\n"
     ]
    }
   ],
   "source": [
    "y = torch.dot(x, x) #y = <x^T.X>\n",
    "y.backward()\n",
    "print(x.grad) #dy/dx tại x :  dy/dx(x) với x = torch.rand(3, requires_grad = True)\n",
    "\n",
    "#Lưu ý x.grad chỉ có ý nghĩa sau khi đã gọi backward(), nếu chưa gọi backward() thì x.grad (dy/dx) == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af55547f-5208-4d28-9d80-fd319108369f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == 2 * x\n",
    "# x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b1c25588-b222-431f-991a-87a86e36da2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.6477, 1.0180, 1.2435])\n"
     ]
    }
   ],
   "source": [
    "z = x.sum() #z = x1 + x2 + x3\n",
    "z.backward()\n",
    "print(x.grad) #ta thấy giá trị của dz/dx lẽ ra phải là [1, 1, 1] do z = x1 + x2 + x3, nhưng x.grad lại cộng cả giá trị của x.grad trước vào, đó là lí do\n",
    "              #ta phải sử dụng x.grad.zero() ở trên\n",
    "              #nếu ta chạy ô này nhiều lần sẽ thấy các grad cộng dồn vào nhau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "269d8696-07ff-4d47-8d0d-3a6bb3c4f5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "z = x.sum()\n",
    "x.grad.zero_()\n",
    "z.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3efb692-9ca3-433e-ab99-6ff2cb802e13",
   "metadata": {},
   "source": [
    "# Vector function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0b9821d7-f3fa-42d6-9ec7-a44072bc3c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7263, 0.4129, 0.7245], requires_grad=True)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3, requires_grad = True)\n",
    "x #Vector cần tính đạo gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6caa77b9-e72f-49d2-ab8c-f5d9691c0d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5275, 0.1705, 0.5249], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x * x\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9ae73dc3-dac6-47e9-8d2c-401770b1d8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4525, 0.8258, 1.4489])\n"
     ]
    }
   ],
   "source": [
    "y.backward(torch.tensor([1.0, 1.0, 1.0]))\n",
    "print(x.grad) #tính [dy1/dx1, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17834a1-c57e-463c-925e-af19f1b19936",
   "metadata": {},
   "source": [
    "# Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fcc989fd-8db4-44e9-b294-10e7acf8258f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.,  5., 13.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1., 2., 3.], requires_grad = True)\n",
    "b = torch.tensor([1., 1., 2.], requires_grad = True)\n",
    "Q = a * a + b * b\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b18820c6-5192-4834-9fe7-b1ba392bd3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 4., 6.]) tensor([2., 2., 4.])\n"
     ]
    }
   ],
   "source": [
    "Q.backward(torch.tensor([1, 1, 1]))\n",
    "print(a.grad, b.grad)\n",
    "\n",
    "#Q = [a1^2 + b1^2, a2^2 + b2^2, a3^2 + b3^2].T = [Q1, Q2, Q3].T\n",
    "#a.grad là tính đạo hàm riêng theo a, nghĩa là tính [dQ1/da1, dQ2/da2, dQ3/da3], tương tự với b.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
