{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c23792ee-5ac5-4d3b-878a-2b507c39691c",
   "metadata": {},
   "source": [
    "## Some experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e148a3a-ce85-45e1-ae9d-cde1e5ac2cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1f76785-27ed-48e5-bff4-02e8c2588fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1., 2., 3.])\n",
    "print(x.dtype, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70869c25-45fb-4097-ac13-ed624eb65647",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d782f2e0-be06-4e27-b692-c55e945ad5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(input_size = 3, hidden_size=2, num_layers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d51993c-5fb7-415d-9a0d-780a477b402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hidden = rnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6e4c6dd-ccf5-4954-a655-514e988d7123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7024, -0.0048]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6baeb51-3dfd-400c-9968-4e63b2d164b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5007,  0.1150],\n",
       "        [ 0.7024, -0.0048]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a879b404-1f51-49ea-96a2-a2cf90605bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([[0.6614, 0.2669, 0.0617]]),\n",
       "  tensor([[ 0.6213, -0.4519, -0.1661]]),\n",
       "  tensor([[-1.5228,  0.3817, -1.0276]]),\n",
       "  tensor([[-0.5631, -0.8923, -0.0583]]),\n",
       "  tensor([[-0.1955, -0.9656,  0.4224]])],\n",
       " (tensor([[[ 0.2673, -0.4212, -0.5107]]]),\n",
       "  tensor([[[-1.5727, -0.1232,  3.5870]]])))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "torch.manual_seed(1)\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)] \n",
    "hidden = (torch.randn(1, 1, 3),\n",
    "          torch.randn(1, 1, 3))\n",
    "inputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e173026-ee03-47f9-9953-523e4f687318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: tensor([[[-0.1124, -0.0653,  0.2808]]], grad_fn=<TransposeBackward0>)\n",
      "hidden: (tensor([[[-0.1124, -0.0653,  0.2808]]], grad_fn=<StackBackward0>), tensor([[[-0.2883, -0.2846,  2.0720]]], grad_fn=<StackBackward0>))\n",
      "out: tensor([[[ 0.1675, -0.0376,  0.4402]]], grad_fn=<TransposeBackward0>)\n",
      "hidden: (tensor([[[ 0.1675, -0.0376,  0.4402]]], grad_fn=<StackBackward0>), tensor([[[ 0.4394, -0.1226,  1.5611]]], grad_fn=<StackBackward0>))\n",
      "out: tensor([[[0.3699, 0.0150, 0.1429]]], grad_fn=<TransposeBackward0>)\n",
      "hidden: (tensor([[[0.3699, 0.0150, 0.1429]]], grad_fn=<StackBackward0>), tensor([[[0.8432, 0.0618, 0.9413]]], grad_fn=<StackBackward0>))\n",
      "out: tensor([[[0.1795, 0.0296, 0.2957]]], grad_fn=<TransposeBackward0>)\n",
      "hidden: (tensor([[[0.1795, 0.0296, 0.2957]]], grad_fn=<StackBackward0>), tensor([[[0.4541, 0.1121, 0.9320]]], grad_fn=<StackBackward0>))\n",
      "out: tensor([[[0.1365, 0.0596, 0.3931]]], grad_fn=<TransposeBackward0>)\n",
      "hidden: (tensor([[[0.1365, 0.0596, 0.3931]]], grad_fn=<StackBackward0>), tensor([[[0.3430, 0.1948, 1.0255]]], grad_fn=<StackBackward0>))\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(input_size=3, hidden_size=3, num_layers=1, batch_first = True)\n",
    "for i in inputs:\n",
    "    # Step through the sequence one element at a time.\n",
    "    # after each step, hidden contains the hidden state.\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "    print('out:', out)\n",
    "    print('hidden:', hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a41b8428-0bb8-45f7-90f2-d6549ef5135f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: tensor([[[-0.1124, -0.0653,  0.2808]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
      "hidden: (tensor([[[-0.1124, -0.0653,  0.2808]]], grad_fn=<StackBackward0>), tensor([[[-0.2883, -0.2846,  2.0720]]], grad_fn=<StackBackward0>))\n",
      "out: tensor([[[ 0.1675, -0.0376,  0.4402]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
      "hidden: (tensor([[[ 0.1675, -0.0376,  0.4402]]], grad_fn=<StackBackward0>), tensor([[[ 0.4394, -0.1226,  1.5611]]], grad_fn=<StackBackward0>))\n",
      "out: tensor([[[0.3699, 0.0150, 0.1429]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
      "hidden: (tensor([[[0.3699, 0.0150, 0.1429]]], grad_fn=<StackBackward0>), tensor([[[0.8432, 0.0618, 0.9413]]], grad_fn=<StackBackward0>))\n",
      "out: tensor([[[0.1795, 0.0296, 0.2957]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
      "hidden: (tensor([[[0.1795, 0.0296, 0.2957]]], grad_fn=<StackBackward0>), tensor([[[0.4541, 0.1121, 0.9320]]], grad_fn=<StackBackward0>))\n",
      "out: tensor([[[0.1365, 0.0596, 0.3931]]], grad_fn=<MkldnnRnnLayerBackward0>)\n",
      "hidden: (tensor([[[0.1365, 0.0596, 0.3931]]], grad_fn=<StackBackward0>), tensor([[[0.3430, 0.1948, 1.0255]]], grad_fn=<StackBackward0>))\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "torch.manual_seed(1)\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)] # indicates that there are 5 sequences to be given as inputs and (1,3) indicates that there is 1 layer with 3 cells\n",
    "hidden = (torch.randn(1, 1, 3),\n",
    "          torch.randn(1, 1, 3)) #initializing h and c values to be of dimensions (1, 1, 3) which indicates there is (1 * 1) - num_layers * num_directions, with batch size of 1 and projection size of 3. \n",
    "                                #Since there is only 1 batch in input, h and c can also have only one batch of data for initialization and the number of cells in both input and output should also match.\n",
    " \n",
    "lstm = nn.LSTM(3, 3) #implying both input and output are 3 dimensional data\n",
    "for i in inputs:\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden) #view to transform the shape of i from (1, 3) into (1, 1, 3) which of the form (Batch, M, N)\n",
    "    print('out:', out)\n",
    "    print('hidden:', hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0930eab6-d447-4963-926c-3bd4970d3431",
   "metadata": {},
   "source": [
    "![image](img/SjnTl.png)\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "747c177d-6e23-4a12-a60b-2f36ecea0581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(0)\n",
    "model = nn.LSTM( input_size = 1, hidden_size = 5, num_layers = 1)\n",
    "x = torch.rand(10, 1, 1)\n",
    "output, (hn, cn) = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "42966de2-cdad-4534-9955-59d23059df12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1499, -0.2004, -0.2470,  0.0773,  0.0717]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d3a6c28d-e6d0-42e7-8ee6-b59659a86511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1499, -0.2004, -0.2470,  0.0773,  0.0717]]],\n",
       "       grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3987b958-6e24-4bb7-80da-2ee570c8a0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(0)\n",
    "model = nn.LSTM(input_size = 1, hidden_size = 50, num_layers = 1)\n",
    "x = torch.rand(50, 1, 1)\n",
    "output, (hn, cn) = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9ade0aed-1cd7-41ac-bcce-bf61071581cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1, 50])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7262a521-309d-43cc-a234-2b152b0a2b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1140, -0.0600, -0.0540,  0.1492, -0.0339, -0.0150, -0.0486,\n",
       "           0.0188,  0.0504,  0.0595, -0.0176, -0.0035,  0.0384, -0.0274,\n",
       "           0.1076,  0.0843, -0.0443,  0.0218, -0.0093,  0.0002,  0.1335,\n",
       "           0.0926,  0.0101, -0.1300, -0.1141,  0.0072, -0.0142,  0.0018,\n",
       "           0.0071,  0.0247,  0.0262,  0.0109,  0.0374,  0.0366,  0.0017,\n",
       "           0.0466,  0.0063,  0.0295,  0.0536,  0.0339,  0.0528, -0.0305,\n",
       "           0.0243, -0.0324,  0.0045, -0.1108, -0.0041, -0.1043, -0.0141,\n",
       "          -0.1222]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9d686531-dafa-40f6-97e5-73b34cec8fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(1,2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3f1720-3e9a-4fe1-b703-49945ef668ad",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "71f63794-b105-4509-9f46-46c7877daaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
    "import torchvision.datasets as datasets  # Standard datasets\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
    "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
    "from torch import nn  # All neural network modules\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    ")  # Gives easier dataset managment by creating mini batches etc.\n",
    "from tqdm import tqdm  # For nice progress bar!\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7d9b69b4-6fc0-4f11-acc4-6dd6709bd33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = 28\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "num_classes = 10\n",
    "sequence_length = 28\n",
    "learning_rate = 0.005\n",
    "batch_size = 64\n",
    "num_epochs = 3\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "24149aca-275d-453b-bc73-66d7ae26d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurrent neural network (many-to-one)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * sequence_length, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e3e8edf2-b02c-46af-afb2-8125bf02fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurrent neural network with GRU (many-to-one)\n",
    "class RNN_GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * sequence_length, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6a014003-fee6-4696-ade1-4777a76d807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurrent neural network with LSTM (many-to-one)\n",
    "class RNN_LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * sequence_length, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(\n",
    "            x, (h0, c0)\n",
    "        )  # out: tensor of shape (batch_size, seq_length, hidden_size), (Batch, M, N) like the MxN matrix\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "286f2ba6-7271-4871-a2e0-689b7abea679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize network (try out just using simple RNN, or GRU, and then compare with LSTM)\n",
    "model = RNN_LSTM(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e6725f-6501-41af-ab3e-c14e2c7669ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Network\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device=device).squeeze(1) #RNN expects the input size of the form (batch size, seq_length, input_size)\n",
    "        targets = targets.to(device=device)      #We're having input size of the form (batch size, C, H, W)\n",
    "\n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent update step/adam step\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4635f7b4-bdd1-4508-bcef-7e7cd0e5b8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on training & test to see how good our model\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    # Set model to eval\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device).squeeze(1)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "    return num_correct / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c51dda-b297-4d4e-8e6b-f376713b8092",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:2f}\")\n",
    "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b81ede-c6e7-4f60-b6c9-936f017c7a02",
   "metadata": {},
   "source": [
    "## Squeeze method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b98e6124-e704-488e-8b06-914aa8806849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 2, 3])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.tensor([[[[1, 2, 3], [1, 2, 3]]], [[[1, 2, 3], [1, 2, 3]]]])\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "78613159-d833-4bcf-86f9-4ed0b770996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "079e6728-173f-424c-b77c-0e0a0a8b1825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
